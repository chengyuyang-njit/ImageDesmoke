{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "usage: ipykernel_launcher.py [-h] -ckp CHECKPOINT -sp SAVE_PATH\n",
      "ipykernel_launcher.py: error: the following arguments are required: -ckp/--CHECKPOINT, -sp/--SAVE_PATH\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "2",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\u001b[1;31m:\u001b[0m 2\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\ycy99\\.conda\\envs\\py39\\lib\\site-packages\\IPython\\core\\interactiveshell.py:3516: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from torchvision import transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "\n",
    "from base.base_model import UNet\n",
    "from dataloader import dataloaders\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "from skimage.metrics import structural_similarity as ssim, peak_signal_noise_ratio as psnr\n",
    "from skimage import color\n",
    "import scipy.signal\n",
    "\n",
    "\n",
    "def wiener_filter(image, kernel_size=5, noise_var = 0.1):\n",
    "    \"\"\"\n",
    "    Apply Wiener filter to each channel of the image.\n",
    "\n",
    "    Parameters:\n",
    "    - image: Input image (numpy array).\n",
    "    - kernel_size: Size of the Wiener filter kernel (default is 5).\n",
    "\n",
    "    Returns:\n",
    "    - filtered_image: Image after applying Wiener filter.\n",
    "    \"\"\"\n",
    "    filtered_image = np.zeros_like(image)\n",
    "    for i in range(image.shape[2]):  # Iterate over R, G, B channels\n",
    "        filtered_image[..., i] = scipy.signal.wiener(image[..., i], mysize=kernel_size, noise = noise_var)\n",
    "    return filtered_image\n",
    "\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    # load the dataset\n",
    "    print(\"[INFO] loading the paired desmoke image dataset...\")\n",
    "\n",
    "    dataset = dataloaders.PairedSmokeImageDataset(\n",
    "        csv_file = '/mmfs1/project/cliu/cy322/datasets/DesmokeData-main/images/paired_images.csv',\n",
    "        root_dir = '/mmfs1/project/cliu/cy322/datasets/DesmokeData-main/images/dataset',\n",
    "        transform = transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "    num_train_samples = int(len(dataset) * config[\"dataloader\"][\"args\"][\"train_split\"]) + 1\n",
    "    num_val_samples = int(len(dataset) * config[\"dataloader\"][\"args\"][\"validation_split\"])\n",
    "    num_test_samples = int(len(dataset) * (1 - config[\"dataloader\"][\"args\"][\"train_split\"] - \n",
    "                                          config[\"dataloader\"][\"args\"][\"validation_split\"]))\n",
    "\n",
    "    (train_data, val_data, test_data) = random_split(dataset, [num_train_samples, num_val_samples, num_test_samples],\n",
    "                                                    generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "    print(\"[INFO] paired desmoke image dataset loaded...\")\n",
    "    return {\"train\":train_data, \"val\":val_data, \"test\": test_data}\n",
    "\n",
    "\n",
    "\n",
    "def visualize_sample(inputs, targets, outputs, filtered_image):\n",
    "    inputs = inputs.cpu().numpy().transpose(1, 2, 0)\n",
    "    targets = targets.cpu().numpy().transpose(1, 2, 0)\n",
    "    outputs = outputs.cpu().numpy().transpose(1, 2, 0)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 4, figsize=(16, 4))\n",
    "    ax[0].imshow(inputs)\n",
    "    ax[0].set_title(\"Input\")\n",
    "    ax[1].imshow(targets)\n",
    "    ax[1].set_title(\"Target\")\n",
    "    ax[2].imshow(outputs)\n",
    "    ax[2].set_title(\"Output\")\n",
    "    ax[3].imshow(filtered_image)\n",
    "    ax[3].set_title(\"Wiener Filter\")\n",
    "    plt.show()\n",
    "\n",
    "def save_sample(inputs, targets, outputs, filtered_image, filename):\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots(1, 4, figsize=(16, 4))\n",
    "    ax[0].imshow(inputs)\n",
    "    ax[0].set_title(\"Input\")\n",
    "    ax[1].imshow(targets)\n",
    "    ax[1].set_title(\"Target\")\n",
    "    ax[2].imshow(outputs)\n",
    "    ax[2].set_title(\"Output\")\n",
    "    ax[3].imshow(filtered_image)\n",
    "    ax[3].set_title(\"Wiener Filter\")\n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n",
    "\n",
    "def save_sample_(inputs, targets, filtered_image, filename):\n",
    "    fig, ax = plt.subplots(1, 3, figsize = (16,3))\n",
    "    ax[0].imshow(inputs)\n",
    "    ax[0].set_title(\"Input\")\n",
    "    ax[1].imshow(targets)\n",
    "    ax[1].set_title(\"Output\")\n",
    "    ax[2].imshow(filtered_image)\n",
    "    ax[2].set_title(\"Wiener Filter\")\n",
    "    plt.savefit(filename)\n",
    "    plt.close()\n",
    "\n",
    "# Test Wiener Filter only\n",
    "def test_wiener():\n",
    "    data = load_data()\n",
    "    eval_loader = DataLoader(data[\"val\"], batch_size = config[\"dataloader\"][\"args\"][\"batch_size\"], shuffle = False)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    for noise_var in [0.01, 0.05, 0.1]:\n",
    "        for window_size in [3, 5, 7, 9]:\n",
    "            number, ssim, psnr = 0, 0, 0\n",
    "            for samples in eval_loader:\n",
    "                filtered_image = wiener_filter(input)\n",
    "                number += 1\n",
    "                ssim += ssim(target, filtered_image, channel_axis = -1 ,data_range = 1)\n",
    "                psnr += psnr(target, filtered_image)\n",
    "                save_sample_(input, target, filtered_image)\n",
    "            print(f\"noise var:{noise_var}, window size:{window_size}, ssim:{ssim/number}, psnr:{psnr/number}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    args = argparse.ArgumentParser(description=\"ImageDesmoke\")\n",
    "    args.add_argument('-ckp', '--CHECKPOINT', default = None, type = str, required = True,\n",
    "                      help = \"path to the checkpoint file of the model that you want to evaluate\")\n",
    "    args.add_argument('-sp', '--SAVE_PATH', default = None, type = str, required = True,\n",
    "                      help = \"Path to save the evaluation results\")\n",
    "    args = args.parse_args()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    ckp = torch.load(args.CHECKPOINT, map_location = device)\n",
    "\n",
    "\n",
    "    print(json.dumps(ckp[\"config\"], indent = 4))\n",
    "    config = ckp[\"config\"]\n",
    "    \n",
    "\n",
    "    # Load model later with:\n",
    "    model = UNet(in_channels=3, out_channels=3).to(device)\n",
    "    model.load_state_dict(ckp[\"state_dict\"])\n",
    "    model.eval()\n",
    "\n",
    "    data = load_data()\n",
    "    eval_loader = DataLoader(data[\"val\"], batch_size = config[\"dataloader\"][\"args\"][\"batch_size\"], shuffle = False)\n",
    "\n",
    "    # with torch.no_grad():\n",
    "    #     number, ssim_u, ssim_w, psnr_u,psnr_w = 0, 0, 0, 0, 0\n",
    "    #     for samples in eval_loader:\n",
    "    #         input = samples[\"smoked_image\"].to(device)\n",
    "    #         target = samples[\"clear_image\"].to(device)\n",
    "    #         output = model(input)\n",
    "    #         # print(input.shape)\n",
    "    #         filename = args.SAVE_PATH + \"/\" + str(number) + \".png\"\n",
    "\n",
    "\n",
    "\n",
    "    #         print(f\"Evaluation Metrics for sample {number}:\")\n",
    "\n",
    "    #         input = input[0].cpu().numpy().transpose(1, 2, 0).astype(np.float32)\n",
    "    #         target = target[0].cpu().numpy().transpose(1, 2, 0).astype(np.float32)\n",
    "    #         output = output[0].cpu().numpy().transpose(1, 2, 0).astype(np.float32)\n",
    "    #         # wiener filter\n",
    "    #         filtered_image = wiener_filter(input, kernel_size = 5, noise_var = 0.1)\n",
    "    #         save_sample(input, target, output, filtered_image, filename)\n",
    "    #         number += 1\n",
    "    #         ssim_u += ssim(target, output, channel_axis = -1 ,data_range = 1)\n",
    "    #         ssim_w += ssim(target, filtered_image, channel_axis = -1 ,data_range = 1)\n",
    "    #         psnr_u += psnr(target, output)\n",
    "    #         psnr_w += psnr(target, filtered_image)\n",
    "    #     print(f\"noise var:0.1 , window size: 5 , ssim wiener:{ssim_w/number},psnr wiener:{psnr_w/number}, ssim u-net:{ssim_u/number}, psnr u-net:{psnr_u/number}\")\n",
    "\n",
    "\n",
    "    for noise_var in [0.01, 0.05, 0.1]:\n",
    "        for window_size in [3, 5, 7, 9]:\n",
    "            number, ssim, psnr = 0, 0, 0\n",
    "            for samples in eval_loader:\n",
    "                input = samples[\"smoked_image\"].to(device)\n",
    "                target = samples[\"clear_image\"].to(device)\n",
    "                filtered_image = wiener_filter(input)\n",
    "                number += 1\n",
    "                ssim += ssim(target, filtered_image, channel_axis = -1 ,data_range = 1)\n",
    "                psnr += psnr(target, filtered_image)\n",
    "                filename = args.SAVE_PATH + \"/\" + str(number) + \"_\" + str(noise_var) + \"_\" + str(window_size) + \".png\"\n",
    "                save_sample(input, target, filtered_image, filename)\n",
    "            print(f\"noise var:{noise_var}, window size:{window_size}, ssim:{ssim_w/number}, psnr:{psnr_w/number}\")\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "# # Get a sample batch\n",
    "# samples = next(iter(eval_loader))\n",
    "# input = samples[\"smoked_image\"].to(device)\n",
    "# target = samples[\"clear_image\"].to(device)\n",
    "# with torch.no_grad():\n",
    "#     output = model(input)\n",
    "\n",
    "# Visualize\n",
    "# visualize_sample(input[0], target[0], output[0])\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
