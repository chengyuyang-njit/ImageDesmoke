{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[ WARN:0@8.713] global loadsave.cpp:268 findDecoder imread_('image1.png'): can't open/read file: check file path/integrity\n",
      "[ WARN:0@8.714] global loadsave.cpp:268 findDecoder imread_('image2.png'): can't open/read file: check file path/integrity\n"
     ]
    },
    {
     "ename": "error",
     "evalue": "OpenCV(4.11.0) /io/opencv/modules/imgproc/src/color.cpp:199: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31merror\u001b[0m                                     Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 12\u001b[0m\n\u001b[1;32m      9\u001b[0m image2 \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mimread(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mimage2.png\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m     11\u001b[0m \u001b[38;5;66;03m# Convert images to grayscale (SSIM expects single-channel images)\u001b[39;00m\n\u001b[0;32m---> 12\u001b[0m gray1 \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(image1, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2GRAY)\n\u001b[1;32m     13\u001b[0m gray2 \u001b[38;5;241m=\u001b[39m cv2\u001b[38;5;241m.\u001b[39mcvtColor(image2, cv2\u001b[38;5;241m.\u001b[39mCOLOR_BGR2GRAY)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Compute SSIM\u001b[39;00m\n",
      "\u001b[0;31merror\u001b[0m: OpenCV(4.11.0) /io/opencv/modules/imgproc/src/color.cpp:199: error: (-215:Assertion failed) !_src.empty() in function 'cvtColor'\n"
     ]
    }
   ],
   "source": [
    "# Test Wiener Filter's performance for dehazing images alone\n",
    "\n",
    "import cv2\n",
    "import numpy as np\n",
    "from skimage.metrics import structural_similarity as ssim\n",
    "\n",
    "\n",
    "# Load images\n",
    "image1 = cv2.imread('image1.png')\n",
    "image2 = cv2.imread('image2.png')\n",
    "\n",
    "# Convert images to grayscale (SSIM expects single-channel images)\n",
    "gray1 = cv2.cvtColor(image1, cv2.COLOR_BGR2GRAY)\n",
    "gray2 = cv2.cvtColor(image2, cv2.COLOR_BGR2GRAY)\n",
    "\n",
    "# Compute SSIM\n",
    "ssim_value = ssim(gray1, gray2)\n",
    "\n",
    "# Compute PSNR\n",
    "psnr_value = cv2.PSNR(image1, image2)\n",
    "\n",
    "\n",
    "print(f\"SSIM: {ssim_value}\")\n",
    "print(f\"PSNR: {psnr_value} dB\")\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import argparse\n",
    "import torch\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.utils.data import random_split\n",
    "from torchvision import transforms\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import torch.optim as optim\n",
    "\n",
    "from base.base_model import UNet\n",
    "from dataloader import dataloaders\n",
    "\n",
    "import json\n",
    "import numpy as np\n",
    "from skimage.metrics import structural_similarity as ssim, peak_signal_noise_ratio as psnr\n",
    "from skimage import color\n",
    "import scipy.signal\n",
    "\n",
    "\n",
    "def wiener_filter(image, kernel_size=5, noise_var = 0.1):\n",
    "    \"\"\"\n",
    "    Apply Wiener filter to each channel of the image.\n",
    "\n",
    "    Parameters:\n",
    "    - image: Input image (numpy array).\n",
    "    - kernel_size: Size of the Wiener filter kernel (default is 5).\n",
    "\n",
    "    Returns:\n",
    "    - filtered_image: Image after applying Wiener filter.\n",
    "    \"\"\"\n",
    "    filtered_image = np.zeros_like(image)\n",
    "    for i in range(image.shape[2]):  # Iterate over R, G, B channels\n",
    "        filtered_image[..., i] = scipy.signal.wiener(image[..., i], mysize=kernel_size, noise = noise_var)\n",
    "    return filtered_image\n",
    "\n",
    "\n",
    "\n",
    "def load_data():\n",
    "    # load the dataset\n",
    "    print(\"[INFO] loading the paired desmoke image dataset...\")\n",
    "\n",
    "    dataset = dataloaders.PairedSmokeImageDataset(\n",
    "        csv_file = '/mmfs1/project/cliu/cy322/datasets/DesmokeData-main/images/paired_images.csv',\n",
    "        root_dir = '/mmfs1/project/cliu/cy322/datasets/DesmokeData-main/images/dataset',\n",
    "        transform = transforms.Compose([transforms.ToTensor()]))\n",
    "\n",
    "    num_train_samples = int(len(dataset) * config[\"dataloader\"][\"args\"][\"train_split\"]) + 1\n",
    "    num_val_samples = int(len(dataset) * config[\"dataloader\"][\"args\"][\"validation_split\"])\n",
    "    num_test_samples = int(len(dataset) * (1 - config[\"dataloader\"][\"args\"][\"train_split\"] - \n",
    "                                          config[\"dataloader\"][\"args\"][\"validation_split\"]))\n",
    "\n",
    "    (train_data, val_data, test_data) = random_split(dataset, [num_train_samples, num_val_samples, num_test_samples],\n",
    "                                                    generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "    print(\"[INFO] paired desmoke image dataset loaded...\")\n",
    "    return {\"train\":train_data, \"val\":val_data, \"test\": test_data}\n",
    "\n",
    "\n",
    "\n",
    "def visualize_sample(inputs, targets, outputs, filtered_image):\n",
    "    inputs = inputs.cpu().numpy().transpose(1, 2, 0)\n",
    "    targets = targets.cpu().numpy().transpose(1, 2, 0)\n",
    "    outputs = outputs.cpu().numpy().transpose(1, 2, 0)\n",
    "\n",
    "    fig, ax = plt.subplots(1, 4, figsize=(16, 4))\n",
    "    ax[0].imshow(inputs)\n",
    "    ax[0].set_title(\"Input\")\n",
    "    ax[1].imshow(targets)\n",
    "    ax[1].set_title(\"Target\")\n",
    "    ax[2].imshow(outputs)\n",
    "    ax[2].set_title(\"Output\")\n",
    "    ax[3].imshow(filtered_image)\n",
    "    ax[3].set_title(\"Wiener Filter\")\n",
    "    plt.show()\n",
    "\n",
    "def save_sample(inputs, targets, outputs, filtered_image, filename):\n",
    "\n",
    "\n",
    "    fig, ax = plt.subplots(1, 4, figsize=(16, 4))\n",
    "    ax[0].imshow(inputs)\n",
    "    ax[0].set_title(\"Input\")\n",
    "    ax[1].imshow(targets)\n",
    "    ax[1].set_title(\"Target\")\n",
    "    ax[2].imshow(outputs)\n",
    "    ax[2].set_title(\"Output\")\n",
    "    ax[3].imshow(filtered_image)\n",
    "    ax[3].set_title(\"Wiener Filter\")\n",
    "    plt.savefig(filename)\n",
    "    plt.close()\n",
    "\n",
    "def save_sample(inputs, targets, filtered_image, filename):\n",
    "    fig, ax = plt.subplots(1, 3, figsize = (16,3))\n",
    "    ax[0].imshow(inputs)\n",
    "    ax[0].set_title(\"Input\")\n",
    "    ax[1].imshow(targets)\n",
    "    ax[1].set_title(\"Output\")\n",
    "    ax[2].imshow(filtered_image)\n",
    "    ax[2].set_title(\"Wiener Filter\")\n",
    "    plt.savefit(filename)\n",
    "    plt.close()\n",
    "\n",
    "# Test Wiener Filter only\n",
    "def test_wiener():\n",
    "    data = load_data()\n",
    "    eval_loader = DataLoader(data[\"val\"], batch_size = config[\"dataloader\"][\"args\"][\"batch_size\"], shuffle = False)\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    for noise_var in [0.01, 0.05, 0.1]:\n",
    "        for window_size in [3, 5, 7, 9]:\n",
    "            number, ssim, psnr = 0, 0, 0\n",
    "            for samples in eval_loader:\n",
    "                filtered_image = wiener_filter(input)\n",
    "                number += 1\n",
    "                ssim += ssim(target, filtered_image, channel_axis = -1 ,data_range = 1)\n",
    "                psnr += psnr(target, filtered_image)\n",
    "                save_sample(input, )\n",
    "            print(f\"noise var:{noise_var}, window size:{window_size}, ssim:{ssim/number}, psnr:{psnr/number}\")\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    args = argparse.ArgumentParser(description=\"ImageDesmoke\")\n",
    "    args.add_argument('-ckp', '--CHECKPOINT', default = None, type = str, required = True,\n",
    "                      help = \"path to the checkpoint file of the model that you want to evaluate\")\n",
    "    args.add_argument('-sp', '--SAVE_PATH', default = None, type = str, required = True,\n",
    "                      help = \"Path to save the evaluation results\")\n",
    "    args = args.parse_args()\n",
    "    device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "    ckp = torch.load(args.CHECKPOINT, map_location = device)\n",
    "\n",
    "\n",
    "    print(json.dumps(ckp[\"config\"], indent = 4))\n",
    "    config = ckp[\"config\"]\n",
    "    \n",
    "\n",
    "    # Load model later with:\n",
    "    model = UNet(in_channels=3, out_channels=3).to(device)\n",
    "    model.load_state_dict(ckp[\"state_dict\"])\n",
    "    model.eval()\n",
    "\n",
    "    data = load_data()\n",
    "    eval_loader = DataLoader(data[\"val\"], batch_size = config[\"dataloader\"][\"args\"][\"batch_size\"], shuffle = False)\n",
    "\n",
    "    # with torch.no_grad():\n",
    "    #     number, ssim_u, ssim_w, psnr_u,psnr_w = 0, 0, 0, 0, 0\n",
    "    #     for samples in eval_loader:\n",
    "    #         input = samples[\"smoked_image\"].to(device)\n",
    "    #         target = samples[\"clear_image\"].to(device)\n",
    "    #         output = model(input)\n",
    "    #         # print(input.shape)\n",
    "    #         filename = args.SAVE_PATH + \"/\" + str(number) + \".png\"\n",
    "\n",
    "\n",
    "\n",
    "    #         print(f\"Evaluation Metrics for sample {number}:\")\n",
    "\n",
    "    #         input = input[0].cpu().numpy().transpose(1, 2, 0).astype(np.float32)\n",
    "    #         target = target[0].cpu().numpy().transpose(1, 2, 0).astype(np.float32)\n",
    "    #         output = output[0].cpu().numpy().transpose(1, 2, 0).astype(np.float32)\n",
    "    #         # wiener filter\n",
    "    #         filtered_image = wiener_filter(input, kernel_size = 5, noise_var = 0.1)\n",
    "    #         save_sample(input, target, output, filtered_image, filename)\n",
    "    #         number += 1\n",
    "    #         ssim_u += ssim(target, output, channel_axis = -1 ,data_range = 1)\n",
    "    #         ssim_w += ssim(target, filtered_image, channel_axis = -1 ,data_range = 1)\n",
    "    #         psnr_u += psnr(target, output)\n",
    "    #         psnr_w += psnr(target, filtered_image)\n",
    "    #     print(f\"noise var:0.1 , window size: 5 , ssim wiener:{ssim_w/number},psnr wiener:{psnr_w/number}, ssim u-net:{ssim_u/number}, psnr u-net:{psnr_u/number}\")\n",
    "\n",
    "\n",
    "    for noise_var in [0.01, 0.05, 0.1]:\n",
    "        for window_size in [3, 5, 7, 9]:\n",
    "            number, ssim, psnr = 0, 0, 0\n",
    "            for samples in eval_loader:\n",
    "                input = samples[\"smoked_image\"].to(device)\n",
    "                target = samples[\"clear_image\"].to(device)\n",
    "                filtered_image = wiener_filter(input)\n",
    "                number += 1\n",
    "                ssim += ssim(target, filtered_image, channel_axis = -1 ,data_range = 1)\n",
    "                psnr += psnr(target, filtered_image)\n",
    "                filename = args.SAVE_PATH + \"/\" + str(number) + \"_\" + str(noise_var) + \"_\" + str(window_size).png\"\n",
    "                save_sample(input, target, filtered_image)\n",
    "            print(f\"noise var:{noise_var}, window size:{window_size}, ssim:{ssim/number}, psnr:{psnr/number}\")\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "# # Get a sample batch\n",
    "# samples = next(iter(eval_loader))\n",
    "# input = samples[\"smoked_image\"].to(device)\n",
    "# target = samples[\"clear_image\"].to(device)\n",
    "# with torch.no_grad():\n",
    "#     output = model(input)\n",
    "\n",
    "# Visualize\n",
    "# visualize_sample(input[0], target[0], output[0])\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
